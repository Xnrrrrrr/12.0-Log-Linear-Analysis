# 12.0-Log-Linear-Analysis

# Log Linear Analysis vs. Chi Square
Both log linear analysis and chi-square tests are used to examine the relationships among categorical variables. However, chi-square tests are limited by their ability to only examine the association between two categorical variables, whereas log linear analysis can be used to examine associations among three or more categorical variables.

Based on the type of data examined in both statistical tests, they both have the same assumptions. These are:

Independence of observations
Each observed frequency is generated by a different individual
Size of expected frequencies greater than or equal to 5
Neither chi-square tests or log linear analysis should be performed when the expected frequency of any cell is less than 5
 

Log Linear Analysis Estimation
A log linear analysis is referred to as “log linear” because we are expressing the model using a linear equation but we are calculating the log of the observed frequencies as our outcome.

Linear Model:
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/31aef968-e8c8-420d-8d66-091b7620b0ad)


The goal of log linear analysis is to identify the simplest model that will fit the data. We do this using backward elimination. In backward elimination we start off by estimating our most complex model. This is known as our saturated model. It includes all possible combinations of our predictors. Because the model has as many estimated parameters as there are data points, there are no degrees of freedom and our model has perfect fit. After testing the saturated model, we examine whether a simpler model can explain the data by eliminating the most complex terms from the model.

Let’s use an example from the text in which data were collected from 270 animals. Variables included animal (dog or cat), training (food as reward or affection as reward), and dance (yes or no). The question we are trying to answer is whether or not there is a relationship among animal type, training, and dancing.
The saturated model for this data would include all 7 terms shown below.
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/90ad50ba-d8bc-4fff-847f-7a457f3c0808)

To do backward elimination we would start with all terms in the model then eliminate the most complex terms until the fit becomes significantly worse.

 

Log Linear Analysis in R
In R we will use the loglm() function to conduct a log linear analysis, which is dependent on the MASS package. It is already pre-installed when your downloaded R so we only need to load this package in using the following syntax before running our log linear analysis:

![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/24916f8a-d71b-43a0-8dc0-49a440f96073)

After loading in the MASS package, we can use the loglm() function, which takes the following form.

![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/32fc2b80-71a0-473c-9934-2af92eaef6cd)

Components of the loglm() Function
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/e969f71e-398d-4616-bc50-8f28c225e04c)

The steps taken to complete a log linear analysis in R are summarized below in Steps 0 to 4.

 

Step 0
Before you run your log linear analysis, you will first need to convert your data object into a contingency table. You can do that using the xtabs() function and the following command

![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/af675563-6fa1-48ad-a6e6-679cf14a46cd)
In the syntax above substitute:

table with any name
categorical variables with the names of the categorical variables you’d like to include in your model
dataFrame with the name of the data object in your Global Environment that contains the data

Step 1
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/6e9c19ac-be11-46e0-b188-950c32454e42)

If it helps you better understand what the previous syntax is doing, below are the equations being tested in each model. If it doesn’t help, feel free to skip these equations.

model0: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X3 + b4X1*X2 + b5X2*X3 + b6X1*X3 + b7X1*X2*X3)
model1: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X3 + b4X1*X2 + b5X2*X3 + b6X1*X3)
model2: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X3 + b4X1*X2 + b5X2*X3)
model3: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X3 + b4X1*X2 + b6X1*X3)
model4: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X3 + b5X2*X3 + b6X1*X3)
model5: ln(Oijk) = (b0+ b1X1 + b2X2 + b3X1*X2)
model6: ln(Oijk) = (b0+ b2X2 + b3X3 + b5X2*X3)
model7: ln(Oijk) = (b0+ b1X1 + b3X3 + b6X1*X3)
model8: ln(Oijk) = (b0+ b1X1 + b3X3)
 
Step 2
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/0f0aa689-9b5b-4cd7-86b9-d55829a9a10f)

Step 3
If your best fitting model is anything but model0, you can also use the CrossTable() function to examine the relationships (see earlier lesson on chi-square analysis). If your best fitting model is model0, you will first need to create subsets of your data before running CrossTable(). You can do this using the following syntax:

![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/f3b21c64-2c13-4502-a5ec-b968c17792f4)

In the syntax above, substitute:

dataFrame with the name of the data object in your Global Environment
classifying variable with the categorical variable being used to split the data
Subcategory1 with the name of the first subcategory of the classifying variable
Subcategory2 with the name of the second subcategory of the classifying variable
 

Full Example in R
The syntax below applies Steps 0 to 4 of the sample syntax to the data set mentioned earlier.

 

Step 0
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/7dc4273e-9075-4058-b4a3-1cdfe97d3e6a)

Step 1
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/51080e14-2a5d-455f-a4a3-a99baf21efec)

Step 2
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/af20e267-2d26-474b-be83-ad877ec8e2a6)

After running model1, we get the following result:
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/bb29137f-ef09-4427-9978-9cf8c12538a9)

The yellow highlighted text above shows the Pearson 
2 test p-value (statistical significance) for the fit of model1. Because this value (5.158036e-06 or .000005158036) is less than .05, it is statistically significant. Because it is statistically significant, this means that the previous model (model0) fits the data better than model1. You would therefore conclude that the best fitting model is model0.

Remember, in the explanation provided above on Backward Elimination, when we use this process we start with the model that is most complex which will always have the best fit (model0). We then progressively try to simplify the model to see if a simpler model can fit the data just as well. The significance tests shown for each model are showing how the current model significantly differs from the previous model in terms of its fit. If it is statistically significant, then that means that the current model has a significantly worse fit than the previous model and should not be used. If it is not statistically significant, then that means the current model could be a viable alternative to the more complex previous model. We test our models progressively. When we find one that is statistically significant, we would stop and choose the previous model as the best fitting model.

 

Step 3
The CrossTable() function is not able to run an analysis on three variables simultaneously so we will need to first create subsets of the data before running our analyses.
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/72ec2608-1704-44ba-b9bd-df7048247d00)


One way to check that your subsets were successfully created is to look in your Global Environment. You should now see "catsub" and "dogsub" under the list of Data objects in your Global Environment. The "catsub" subset will have "200 obs." (which means 200 observations) and the "dogsub" subset will have "70 obs." (which means 70 observations). You can therefore see that your data set containing 270 observations has now been split into two portions; one that contains the data for cats and the other that contains the data for dogs. If either of these subsets had "0 obs." then you would need to double check your syntax to make sure you didn't add any extra spaces/characters (e.g., " Dog") or misspelled the name of the subcategory (e.g., "Dgo").

Also make a note of the double equal sign (==) being used in the subset() function as opposed to a single equal sign (=). Using a single equal sign in the subset function (e.g., dogsub = subset(catdog, Animal = "Dog") would assign the entire data set to that subset (hence defeating the purpose of subsetting), whereas using a double equal sign in the subset function (e.g., dogsub = subset(catdog, Animal == "Dog") would only assign the subcategory of the variable Animal that matches the word "Dog". You can check that you did this successfully by looking in the Global Environment. If after running your subset you have 270 obs. in dogsub instead of 70 obs. then you more than likely used a single equal sign in your subset function as opposed a double equal sign.

 

After creating your subsets by splitting the data based on the subcategories of Animal, you can run a chi-square test to evaluate the relationship between Training and Dance for each subset of your data. Make a note that at this point, you are no longer referencing the original catdog data set in your CrossTable() function. You are referencing the subsets of data created above. These are catsub and dogsub.
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/5c575a6e-d0d5-4962-966c-1ab6157eece9)

Cross Table Results for the Cats Subset
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/11f06e05-38ed-4e75-a6cc-f73b2d34eb0b)

Cross Table Results for the Dogs Subset
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/34ecb496-3a1f-46e1-9603-a5e8202d5584)

nterpretation of Results
Our results show that the effect of training on dancing varies based on the type of animal examined.

For cats, the relationship between training and dancing was statistically significant (χ2 = 25.36, df = 1, p < .001) with a moderate effect size (Φ = 0.36). Drilling down into these analyses we can see that more cats than we expected danced when given food as a reward (std. residual = 3.568). Similarly, less cats than we would expect failed to dance when given food as a reward (std. residual = -2.794).

For dogs, the relationship between training and dancing was statistically significant (χ2 = 3.93, df = 1, p = .047) with a weak effect size (Φ = 0.24). Drilling down into these analyses we can see that there was no clear direction in the standardized residuals to determine what was driving these effects. Caution should therefore be exercised in interpreting the significance of the results for dogs.

In sum, when getting animals to dance, training type seems to matter more for cats than for dogs.

 

Visualizing Results in R
Given that the CrossTable() function can only be used with two variables at a time, a more accurate way to visualize and interpret the relationship among three variables is by using a mosaic plot. The syntax below shows how to create a mosaic plot for this data.

![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/1ddddfc6-212c-4ad2-bbe9-32f84c75a8de)

NOTE: If you're having trouble reading a mosaic plot that includes three variables, click the Zoom magnifying glass in the Plots panel in RStudio. This will enable you to zoom into the plot.
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/0ff092fb-02e6-4f51-8d3e-42297516b7d6)

The results from the syntax shown above is provided below along with an interpretation.
![image](https://github.com/Xnrrrrrr/12.0-Log-Linear-Analysis/assets/133546385/f72fc41c-dc65-49ae-8a27-bcde91b013bd)

This plot shows that the relationship between training and dancing varied across animals.

For the cats in the sample, more received affection as a reward than food. Less cats than expected danced when receiving affection as a reward, more cats than expected did not dance when receiving affection as a reward, and less cats than expected did not dance when receiving food as a reward.

For the dogs in the sample, an equal number received affection and food as a reward. Less dogs than expected did not dance when receiving affection as a reward and more dogs than expected danced when food as a reward.

 
